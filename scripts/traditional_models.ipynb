{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.tsv',sep='\\t',header=None,dtype={0:str,1:str})\n",
    "dev = pd.read_csv('dev.tsv',sep='\\t',header=None,dtype={0:str,1:str})\n",
    "test = pd.read_csv('test.tsv',sep='\\t',header=None,dtype={0:str,1:str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_labels(df):\n",
    "    y = []\n",
    "\n",
    "    for label in df[0]:\n",
    "        label_vec = []\n",
    "\n",
    "        for cat in label:\n",
    "            label_vec.append(int(cat))\n",
    "\n",
    "\n",
    "        y.append(np.array(label_vec))\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(train_file):\n",
    "    train = pd.read_csv(train_file,sep='\\t',header=None,dtype={0:str,1:str})\n",
    "    dev = pd.read_csv('dev.tsv',sep='\\t',header=None,dtype={0:str,1:str})\n",
    "    test = pd.read_csv('test.tsv',sep='\\t',header=None,dtype={0:str,1:str})\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    train_X = tfidf_vectorizer.fit_transform(train[1])\n",
    "    train_y = vectorize_labels(train)\n",
    "\n",
    "    dev_X = tfidf_vectorizer.transform(dev[1])\n",
    "    dev_y = vectorize_labels(dev)\n",
    "\n",
    "    test_X = tfidf_vectorizer.transform(test[1])\n",
    "    test_y = vectorize_labels(test)\n",
    "\n",
    "    clf = OneVsRestClassifier(SVC(probability=True, kernel='linear'))\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    dev_pred = clf.predict(dev_X)\n",
    "    test_pred = clf.predict(test_X)\n",
    "    \n",
    "    return clf, dev_y, test_y, dev_pred, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, dev_y, test_y, dev_pred, test_pred = train_svm('train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_on_file(clsf, train_file, test_file):\n",
    "    train = pd.read_csv(train_file,sep='\\t',header=None,dtype={0:str,1:str})\n",
    "    dev = pd.read_csv(test_file,sep='\\t',header=None,dtype={0:str,1:str})\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    train_X = tfidf_vectorizer.fit_transform(train[1])\n",
    "    \n",
    "    dev_X = tfidf_vectorizer.transform(dev[1])\n",
    "    dev_y = vectorize_labels(dev)\n",
    "    \n",
    "    dev_pred = clsf.predict(dev_X)\n",
    "\n",
    "    print(metrics.accuracy_score(dev_y, dev_pred),metrics.f1_score(dev_y, dev_pred, average='micro'))\n",
    "    \n",
    "    return dev_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5880149812734082 0.7235859124866597\n"
     ]
    }
   ],
   "source": [
    "dev_pred = eval_model_on_file(clf, 'train.tsv','dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26 0.5560165975103735\n"
     ]
    }
   ],
   "source": [
    "eval_model_on_file(clf, 'train.tsv','cord19_test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50\n",
      "0.5617977528089888 0.6969529085872576\n",
      "0.580625 0.7259548369110677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfs = {}\n",
    "\n",
    "for ratio in ['0.50']:\n",
    "    print(ratio)\n",
    "    clf, dev_y, test_y, dev_pred, test_pred = train_svm('train_{}.tsv'.format(ratio))\n",
    "    \n",
    "    clfs[ratio] = clf\n",
    "    \n",
    "    print(metrics.accuracy_score(dev_y, dev_pred),metrics.f1_score(dev_y, dev_pred, average='micro'))\n",
    "    print(metrics.accuracy_score(test_y, test_pred),metrics.f1_score(test_y, test_pred, average='micro'))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_X = tfidf_vectorizer.fit_transform(train[1])\n",
    "train_y = vectorize_labels(train)\n",
    "\n",
    "dev_X = tfidf_vectorizer.transform(dev[1])\n",
    "dev_y = vectorize_labels(dev)\n",
    "\n",
    "test_X = tfidf_vectorizer.transform(test[1])\n",
    "test_y = vectorize_labels(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = OneVsRestClassifier(LogisticRegression())\n",
    "lr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.533083645443196, 0.6745230078563412)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_pred = lr.predict(dev_X)\n",
    "test_pred = lr.predict(test_X)\n",
    "\n",
    "metrics.accuracy_score(dev_y, dev_pred),metrics.f1_score(dev_y, dev_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.585, 0.7223178427997704)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(test_y, test_pred),metrics.f1_score(test_y, test_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_preds = pickle.load(open('../hedwig-data/datasets/LitCovid/dev_longformer-base_train_0.05.tsv_1024_metrics.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(dev_y[1:], dev_preds[0],average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(dev_y[1:], dev_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [len(t.split()) for t in train[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dev Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Dev F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biobert_cord19_512</th>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.674375</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.813176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biobert_pretrained_run_512</th>\n",
       "      <td>0.667917</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.802748</td>\n",
       "      <td>0.787938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biobert_train.tsv_512</th>\n",
       "      <td>0.658750</td>\n",
       "      <td>0.674171</td>\n",
       "      <td>0.802457</td>\n",
       "      <td>0.813089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biobert_train_0.01.tsv_512</th>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.387117</td>\n",
       "      <td>0.414130</td>\n",
       "      <td>0.405383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biobert_train_0.05.tsv_512</th>\n",
       "      <td>0.567500</td>\n",
       "      <td>0.561601</td>\n",
       "      <td>0.688985</td>\n",
       "      <td>0.689312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biobert_train_0.10.tsv_512</th>\n",
       "      <td>0.631250</td>\n",
       "      <td>0.639149</td>\n",
       "      <td>0.750259</td>\n",
       "      <td>0.756517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biobert_train_0.20.tsv_512</th>\n",
       "      <td>0.653750</td>\n",
       "      <td>0.666041</td>\n",
       "      <td>0.797115</td>\n",
       "      <td>0.793867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Dev Acc  Test Acc    Dev F1   Test F1\n",
       "biobert_cord19_512          0.390000  0.674375  0.692308  0.813176\n",
       "biobert_pretrained_run_512  0.667917  0.645000  0.802748  0.787938\n",
       "biobert_train.tsv_512       0.658750  0.674171  0.802457  0.813089\n",
       "biobert_train_0.01.tsv_512  0.385000  0.387117  0.414130  0.405383\n",
       "biobert_train_0.05.tsv_512  0.567500  0.561601  0.688985  0.689312\n",
       "biobert_train_0.10.tsv_512  0.631250  0.639149  0.750259  0.756517\n",
       "biobert_train_0.20.tsv_512  0.653750  0.666041  0.797115  0.793867"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_dict = {}\n",
    "\n",
    "for filename in glob.glob('../hedwig-data/datasets/LitCovid/dev*biobert*512*metrics*'):\n",
    "    metric_tuple = pickle.load(open(filename,'rb'))\n",
    "    acc_dev ,_,_,f1_dev, _ = metric_tuple[0]\n",
    "        \n",
    "    try:\n",
    "        metric_tuple = pickle.load(open(filename.replace('dev','test'),'rb'))\n",
    "        acc_test ,_,_,f1_test,_ = metric_tuple[0]\n",
    "    except:\n",
    "        print(filename)\n",
    "        f1_test = 0\n",
    "        acc_test = 0\n",
    "        \n",
    "    metric_dict[filename] = [acc_dev,acc_test,f1_dev,f1_test]\n",
    "    \n",
    "m_list = list(metric_dict.values())\n",
    "m_names = ['Dev Acc','Test Acc', 'Dev F1', 'Test F1']\n",
    "\n",
    "pd.DataFrame(m_list,columns=m_names,index=[m.split('/')[-1][4:-10] for m in metric_dict.keys()]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metric_dict = {}\n",
    "\n",
    "# dev_y = [d[:-1] for d in dev_y]\n",
    "# test_y = [d[:-1] for d in test_y]\n",
    "\n",
    "for filename in glob.glob('../hedwig-data/datasets/LitCovid/dev*long*train.tsv*prediction*'):\n",
    "    dev_preds = pickle.load(open(filename,'rb'))[0]\n",
    "\n",
    "#     dev_preds = [d[:-1] for d in dev_preds]\n",
    "\n",
    "    f1_dev = metrics.f1_score(dev_y[1:], dev_preds,average='micro')\n",
    "    acc_dev = metrics.accuracy_score(dev_y[1:], dev_preds)\n",
    "\n",
    "    try:\n",
    "        test_preds = pickle.load(open(filename.replace('dev','test'),'rb'))[0]\n",
    "#         test_preds = [d[:-1] for d in test_preds]\n",
    "\n",
    "        f1_test = metrics.f1_score(test_y[1:], test_preds,average='micro')\n",
    "        acc_test = metrics.accuracy_score(test_y[1:], test_preds)\n",
    "    except:\n",
    "        print(filename)\n",
    "        f1_test = 0\n",
    "        acc_test = 0\n",
    "        \n",
    "    metric_dict[filename] = [acc_dev,acc_test,f1_dev,f1_test]\n",
    "    \n",
    "m_list = list(metric_dict.values())\n",
    "m_names = ['Dev Acc','Test Acc', 'Dev F1', 'Test F1']\n",
    "\n",
    "pd.DataFrame(m_list,columns=m_names,index=[m.split('/')[-1][4:-10] for m in metric_dict.keys()]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'model': metrics.keys(),'m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "categorization",
   "language": "python",
   "name": "categorization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
